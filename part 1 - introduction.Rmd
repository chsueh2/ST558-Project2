---
title: "ST558 Porject 1: Part 1"
author: "Bridget Knapp and Chien-Lan Hsueh"
institute: Online Statistics Master Program, NCSU
date: "`r Sys.Date()`"
output:
  html_notebook:
    theme: cerulean
    highlight: haddock
    code_folding: none
  html_document:
    df_print: paged
---

```{r include=FALSE}
knitr::opts_chunk$set(fig.path = "./images/")
```


## Introduction Section

> You should have an introduction section that briefly describes the data and the variables you have to work with (just discuss the ones you want to use). Your target variables is the shares variable. You should also mention the purpose of your analysis and the methods you’ll use to model the response. You’ll describe those in more detail later. 
>
> This section should be done by the ‘second’ group member. 



## Start here...

```{r render, eval = FALSE}
#this is the code I used to render this document before I committed changes to the repository
rmarkdown::render("part 1 - introduction.Rmd",
                  output_format = "github_document",
                  output_options = list(
                    toc = TRUE,
                    html_preview=FALSE) 
)

```

# About the Data

We are going to get our data from the UCI Machine Learning Repository. Essentially, it’s a website with over 600 data sets for people to practice coding and machine learning. We are going to use the Online News Popularity Data Set, which summarizes a variety of aspects about articles published by Mashable, an American news website, over the course of two years. Some of the aspects include:

+ Number of words in the title and in the content
+ Number of links, images, and videos
+ Type, or channel, of news (Lifestyle, Entertainment, Business, Social Media, Tech, or World)
+ Minimum, maximum, and average number of shares for the worst, best, and average keyword 
+ When the article was published (Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday, or a weekend)?
+ Minimum, maximum, and average polarity of positive and negative words in the article

We will ignore the URL of the article and the number of days between the article publication and the dataset acquisition because they are non-predictive.

# What We Are Going to Do

The purpose of this repository is to automatically generate reports for each channel of news that summarize the data and to predict the number of shares based on chosen aspects of interest. To make our predictions, we will split the data up into a training and a test set and, using the training set, make a linear regression model and an ensemble tree-based model, specifically a random forest model and a boosted tree model.








Let's say you're interested in entertainment news and you would like to predict the number shares based on different criteria. Luckily, this repository is here to help. This will help you learn about our data set, make predictions, and create automated Markdown reports. First, let's look at the data:

We want to predict the number of `shares` a certain type of news receives. The news type is described in the `data_channel_is_*` columns. There are six types: Lifestyle, Entertainment, Business, Social Media, Tech, and World. The data also includes columns for the day of the week the article was published (`weekday_is_*`), the best, worst, and average keywords based on number of shares (`kw_*`); and negative or positive popularity (`*_polarity`).

To predict the number of 'shares', we will use a linear regression model and an ensemble tree-based model. In a linear regression model, the response for the _i^th^_ observation (Y~i~) is calculated by using an explanatory variable for the _i^th^_ observation (x~i~) to calculate the y-intercept (B~0~), slope (B~1~), and error (E~i~):

Y~i~ = B~0~ + B~1~ x~i~ + E~i~

An ensemble tree-based model takes the average across many trees. Here, we'll use a random forest model, which creates many trees from bootstrap samples. Bootstrapping is the process of taking many samples from our data, calulating a statistic for each sample, and then averaging the results. We'll also use a boosted tree model, which creates many trees based on the residuals (observed-predicted) of the previous set (the user specifies how many times this is repeated).
