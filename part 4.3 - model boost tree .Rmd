---
title: "ST558 Porject 1: Part 4.3"
author: "Bridget Knapp and Chien-Lan Hsueh"
institute: Online Statistics Master Program, NCSU
date: "`r Sys.Date()`"
output:
  html_notebook:
    theme: cerulean
    highlight: haddock
    code_folding: none
  html_document:
    df_print: paged
---

```{r include=FALSE}
knitr::opts_chunk$set(fig.path = "./images/")
```


## Modeling - boosted tree

> Youâ€™ll need to split the data into a training (70% of the data) and test set (30% of the data). Use set.seed() to make things reproducible.
>
> The goal is to create models for predicting the number of shares in some way. Each group member should contribute a linear regression model and an ensemble tree-based model. As we are automating things, describing the chosen model is tough, so no need to worry about that. 
>
> The first group member should fit a random forest model and the second group member should fit a boosted tree model. Both models should be chosen using cross-validation. 
>
> Prior to the models fit using linear regression, the first group member should provide a short but thorough explanation of the idea of a linear regression model. 
>
> Prior to each ensemble model, you should provide a short but reasonably thorough explanation of the ensemble model you are using (so one for each group member).


```{r, include = FALSE}
knitr::knit("part 2 - data.Rmd", output = tempfile())
```

## Start here...

# Boosted Tree: Definition

Tree based methods allow the user to split up the predictor space(s) into different regions and then make predictions based off those regions. A boosted tree model, which creates many trees based on the residuals (observed-predicted) of the previous set (the user specifies how many times this is repeated).

